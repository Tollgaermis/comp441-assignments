{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn9aNItt4okk"
      },
      "source": [
        "# Koç University, Deep Learning Course (COMP541) <br/> Assignment 4: Graph Neural Networks and Transformers\n",
        "### Due on January 2, 2025 (23:59:59)\n",
        "\n",
        "In this assignment, you will implement the vanilla version of Graph Convolution\n",
        "Networks (GCN) [Kipf and Welling \\(2016\\)](https://arxiv.org/abs/1609.02907) and Graph Attention Networks (GAT) [Veličković, et al.\n",
        "\\(2018\\)](https://openreview.net/forum?id=rJXMpikCZ)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ab_-ToD6EWN"
      },
      "source": [
        "## Background\n",
        "### Basics of GCN\n",
        "Recall from the lectures, the goal of a GCN is to learn a function of signals features on a graph $G = (V, E)$, which takes as inputs:\n",
        "1. he input features of each node, $x_i ∈ R^F$ (in matrix form: $X ∈ R^{|V |×F}$ )\n",
        "2. some information about the graph structure, typically the adjacency matrix $A$\n",
        "\n",
        "Each convolutional layer can be written as $H^{(l+1)} = f(H^{(l)}, A)$ for some function $f$. The function $f$ we are using for this assignment is in the form of $f(H^{(l)}, A) = σ(\\hat{D}^{-1/2}\\hat{A}\\hat{D}^{-1/2}H^{(l)}W^{(l)})$, where $\\hat{A} = A + I$ and $\\hat{D}$ is the diagonal node degree matrix ($D^{-1}\\hat{A}$ normalizes $\\hat{A}$ such that all rows sum to one). Let $\\tilde{A} = \\hat{D}^{-1/2}\\hat{A}\\hat{D}^{-1/2}$. The GCN we will implement takes two convolution layers, $Z = f(X, A) = softmax(\\tilde{A}~.~Dropout(ReLU(\\tilde{A}XW^{(0)}))~.W^{(1)})$\n",
        "\n",
        "### Basics of GAT\n",
        "Graph Attention Network (GAT) is a novel convolution-style neural network. It operates on graph-structured data and leverages masked self-attentional layers. In this assignment, we will implement the graph attention layer.\n",
        "\n",
        "### Dataset\n",
        "The dataset we used for this assignment is Cora ([Sen et al. \\(2008\\)](http://www.cs.iit.edu/~ml/pdfs/sen-aimag08.pdf)). Cora is one of standard citation network benchmark dataset (just like MNIST dataset for computer vision tasks). It that consists of 2708 scientific publications and 5429 links. Each publication is classified into one of 7 classes. Each publication is described by a word vector (length 1433) that indicates the absence/presence of the corresponding word. This is used as the features of each node for our experiment. The task is to perform node classification (predict which class each node belongs to)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTsdgLCErn4Z"
      },
      "source": [
        "## Experiments\n",
        "Experiments:\n",
        "Open GCN notebook on Colab and implement the following parts.\n",
        "1. Implementation of Graph Convolution Layer: Complete the code for `GraphConvolution` Class\n",
        "2. Implementation of Graph Convolution Network: Complete the code for `GCN` Class\n",
        "3. Train your Graph Convolution Network: After implementing the required classes, now you can train your GCN. We want you to play with the architecture (such as the number of Graph Convolution Layers, usage of Dropout etc.) and the hyperparameters, and report your results in various settings.\n",
        "4. Implementation of Graph Attention Layer: Complete the code for `GraphAttentionLayer` Class\n",
        "5. Train your Graph Convolution Network: After implementing the required classes, now you can train your GAT. Again, you are need to play with the structure and the hyperparameters and conduct various experiments.\n",
        "6. Compare your models: Compare the evaluation results for Vanilla GCN and GAT. Comment on the discrepancy in their performance (if any) and briefly explain why you think it’s the case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImLCXm8IsSS2"
      },
      "source": [
        "# Download the Cora data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xRN47p1SKRgP",
        "outputId": "d8523189-d1fc-4f70-9acb-4df5bc7fbf65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-03 21:45:41--  https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\n",
            "Resolving linqs-data.soe.ucsc.edu (linqs-data.soe.ucsc.edu)... 128.114.47.74\n",
            "Connecting to linqs-data.soe.ucsc.edu (linqs-data.soe.ucsc.edu)|128.114.47.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168052 (164K) [application/x-gzip]\n",
            "Saving to: ‘cora.tgz’\n",
            "\n",
            "cora.tgz            100%[===================>] 164.11K   326KB/s    in 0.5s    \n",
            "\n",
            "2025-01-03 21:45:42 (326 KB/s) - ‘cora.tgz’ saved [168052/168052]\n",
            "\n",
            "cora/\n",
            "cora/README\n",
            "cora/cora.cites\n",
            "cora/cora.content\n"
          ]
        }
      ],
      "source": [
        "! wget https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\n",
        "! tar -zxvf cora.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXIYzURA4OKg"
      },
      "source": [
        "# import modules and set random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uJQYMX02_z0M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "seed = 0\n",
        "\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgOv1h7YsK-5"
      },
      "source": [
        "# Loading and preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kXPHN61i9keB"
      },
      "outputs": [],
      "source": [
        "def encode_onehot(labels):\n",
        "    # The classes must be sorted before encoding to enable static class encoding.\n",
        "    # In other words, make sure the first class always maps to index 0.\n",
        "    classes = sorted(list(set(labels)))\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
        "                    enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
        "                             dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "\n",
        "def load_data(path=\"/content/cora/\", dataset=\"cora\", training_samples=140):\n",
        "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
        "    print('Loading {} dataset...'.format(dataset))\n",
        "\n",
        "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n",
        "                                        dtype=np.dtype(str))\n",
        "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
        "    labels = encode_onehot(idx_features_labels[:, -1])\n",
        "\n",
        "    # build graph\n",
        "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
        "    idx_map = {j: i for i, j in enumerate(idx)}\n",
        "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
        "                                    dtype=np.int32)\n",
        "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
        "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
        "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
        "                        shape=(labels.shape[0], labels.shape[0]),\n",
        "                        dtype=np.float32)\n",
        "\n",
        "    # build symmetric adjacency matrix\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    features = normalize(features)\n",
        "    adj = adj + sp.eye(adj.shape[0])\n",
        "    adj = normalize_adj(adj)\n",
        "\n",
        "    # Random indexes\n",
        "    idx_rand = torch.randperm(len(labels))\n",
        "    # Nodes for training\n",
        "    idx_train = idx_rand[:training_samples]\n",
        "    # Nodes for validation\n",
        "    idx_val= idx_rand[training_samples:]\n",
        "\n",
        "    adj = torch.FloatTensor(np.array(adj.todense()))\n",
        "    features = torch.FloatTensor(np.array(features.todense()))\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\n",
        "\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_val = torch.LongTensor(idx_val)\n",
        "\n",
        "    return adj, features, labels, idx_train, idx_val\n",
        "\n",
        "def normalize_adj(mx):\n",
        "    \"\"\"symmetric normalization\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
        "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
        "    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
        "    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzCZVd1JsbHr"
      },
      "source": [
        "## Check the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KlsKjMKx8_b7",
        "outputId": "e6c6020d-44d8-4c91-b707-b2222a31416a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cora dataset...\n"
          ]
        }
      ],
      "source": [
        "adj, features, labels, idx_train, idx_val = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mxrv21rLnpiZ",
        "outputId": "1c732dfe-8ada-4c8f-d70e-2bf1ebfaff12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1667, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.2000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.2000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2500]])\n",
            "torch.Size([2708, 2708])\n"
          ]
        }
      ],
      "source": [
        "print(adj)\n",
        "print(adj.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lWrDf0iWnpqV",
        "outputId": "8cb9e558-17a6-45ba-d130-b2b45d232171",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "torch.Size([2708, 1433])\n"
          ]
        }
      ],
      "source": [
        "print(features)\n",
        "print(features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TUkt2JJdsuA2",
        "outputId": "eeb630ad-1bdc-4873-8a26-7e8d90b35fdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 5, 4,  ..., 1, 0, 2])\n",
            "tensor([0, 1, 2, 3, 4, 5, 6])\n",
            "2708\n"
          ]
        }
      ],
      "source": [
        "print(labels)\n",
        "print(labels.unique())\n",
        "print(len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iGP18jNAs1Gp",
        "outputId": "5cc5fcae-ad4f-4032-fc95-c75cee5698b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140\n",
            "2568\n"
          ]
        }
      ],
      "source": [
        "print(len(idx_train))\n",
        "print(len(idx_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKHEyXp1EVdo"
      },
      "source": [
        "# Part 1: Graph Attention Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx15HdotKnt_"
      },
      "source": [
        "## Part 1.1: Graph attention layer\n",
        "A GAT is made up of multiple such layers. In this section, you will implement a single graph attention layer. Similar to the `GraphConvolution()`, this `GraphAttentionLayer()` module takes $\\mathbf{h} = \\{ \\overrightarrow{h_1}, \\overrightarrow{h_2}, \\dots, \\overrightarrow{h_N} \\}$ where $\\overrightarrow{h_i} \\in \\mathbb{R}^F$ as input and outputs $\\mathbf{h'} = \\{ \\overrightarrow{h'_1}, \\overrightarrow{h'_2}, \\dots, \\overrightarrow{h'_N} \\}$, where $\\overrightarrow{h'_i} \\in \\mathbb{R}^{F'}$. However, instead of weighing each neighbouring node based on the adjacency matrix, we will use self attention to learn the relative importance of each neighbouring node. Recall from HW4 where you are asked to write out the equation for single headed attention, here we will implement multi-headed attention, which involves the following steps:\n",
        "\n",
        "\n",
        "### The initial transformation\n",
        "In GCN above, you have completed similar transformation. But here, we need to define a weight matrix and perform this transformation for each head: $\\overrightarrow{s^k_i} = \\mathbf{W}^k \\overrightarrow{h_i}$. We will perform a single linear transformation and then split it up for each head later. Note the input $\\overrightarrow{h}$ has shape `[n_nodes, in_features]` and $\\overrightarrow{s}$ has shape of `[n_nodes, n_heads * n_hidden]`. Remember to reshape $\\overrightarrow{s}$ has shape of `[n_nodes, n_heads, n_hidden]` for later uses. Note: set `bias=False` for this linear transformation.\n",
        "\n",
        "### attention score\n",
        "We calculate these for each head $k$. Here for simplicity of the notation, we omit $k$ in the following equations. The attention scores are defined as the follows:\n",
        "$e_{ij} = a(\\mathbf{W} \\overrightarrow{h_i}, \\mathbf{W} \\overrightarrow{h_j}) =a(\\overrightarrow{s_i}, \\overrightarrow{s_j})$,\n",
        "where $e_{ij}$ is the attention score (importance) of node $j$ to node $i$.\n",
        "We will have to calculate this for each head. $a$ is the attention mechanism, that calculates the attention score. The paper concatenates $\\overrightarrow{s_i}$, $\\overrightarrow{s_j}$ and does a linear transformation with a weight vector $\\mathbf{a} \\in \\mathbb{R}^{2 F'}$ followed by a $\\text{LeakyReLU}$. $$e_{ij} = \\text{LeakyReLU} \\Big(\n",
        "\\mathbf{a}^\\top \\Big[ \\overrightarrow{s_i} \\Vert \\overrightarrow{s_j}  \\Big] \\Big)$$\n",
        "\n",
        "#### How to vectorize this? Some hints:\n",
        "1. `tensor.repeat()` gives you $\\{\\overrightarrow{s_1}, \\overrightarrow{s_2}, \\dots, \\overrightarrow{s_N}, \\overrightarrow{s_1}, \\overrightarrow{s_2}, \\dots, \\overrightarrow{s_N}, ...\\}$.\n",
        "\n",
        "2. `tensor.repeat_interleave()` gives you\n",
        "$\\{\\overrightarrow{s_1}, \\overrightarrow{s_1}, \\dots, \\overrightarrow{s_1}, \\overrightarrow{s_2}, \\overrightarrow{s_2}, \\dots, \\overrightarrow{s_2}, ...\\}$.\n",
        "\n",
        "3. concatenate to get $\\Big[\\overrightarrow{s_i} \\Vert \\overrightarrow{s_j} \\Big]$ for all pairs of $i, j$. Reshape $\\overrightarrow{s_i} \\Vert \\overrightarrow{s_j}$ has shape of `[n_nodes, n_nodes, n_heads, 2 * n_hidden]`\n",
        "\n",
        "4. apply the attention layer and non-linear activation function to get $e_{ij} = \\text{LeakyReLU} \\Big( \\mathbf{a}^\\top \\Big[ \\overrightarrow{s_i} \\Vert \\overrightarrow{s_j}  \\Big] \\Big)$, where $\\mathbf{a}^\\top$ is a single linear transformation that maps from dimension `n_hidden * 2` to `1`. Note: set the `bias=False` for this linear transformation. $\\mathbf{e}$ is of shape `[n_nodes, n_nodes, n_heads, 1]`. Remove the last dimension `1` using `squeeze()`.\n",
        "\n",
        "\n",
        "#### Perform softmax\n",
        "First, we need to mask $e_{ij}$ based on adjacency matrix. We only need to sum over the neighbouring nodes for the attention calculation. Set the elements in $e_{ij}$ to $- \\infty$ if there is no edge from $i$ to $j$ for the softmax calculation. We need to do this for all heads and the adjacency matrix is the same for each head. Use `tensor.masked_fill()` to mask $e_{ij}$ based on adjacency matrix for all heads. Hint: reshape the adjacency matrix to `[n_nodes, n_nodes, 1]` using `unsqueeze()`.\n",
        "Now we are ready to normalize attention scores (or coefficients) $$\\alpha_{ij} = \\text{softmax}_j(e_{ij}) =  \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}_i} \\exp(e_{ik})}$$\n",
        "\n",
        "#### Apply dropout\n",
        "Apply the dropout layer. (this step is easy)\n",
        "\n",
        "#### Calculate final output for each head\n",
        "$$\\overrightarrow{h'^k_i} = \\sum_{j \\in \\mathcal{N}_i} \\alpha^k_{ij} \\overrightarrow{s^k_j}$$\n",
        "\n",
        "\n",
        "#### Concat or Mean\n",
        "Finally we concateneate the transformed features: $\\overrightarrow{h'_i} = \\Bigg\\Vert_{k=1}^{K} \\overrightarrow{h'^k_i}$. In the code, we only need to reshape the tensor to shape of `[n_nodes, n_heads * n_hidden]`. Note that if it is the final layer, then it doesn't make sense to do concatenation anymore. Instead, we sum over the `n_heads` dimension: $\\overrightarrow{h'_i} = \\frac{1}{K} \\sum_{k=1}^{K} \\overrightarrow{h'^k_i}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wVu7rcOuAUZz"
      },
      "outputs": [],
      "source": [
        "class GraphAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features: int, out_features: int, n_heads: int,\n",
        "                 is_concat: bool = True,\n",
        "                 dropout: float = 0.6,\n",
        "                 alpha: float = 0.2):\n",
        "        \"\"\"\n",
        "        in_features: F, the number of input features per node\n",
        "        out_features: F', the number of output features per node\n",
        "        n_heads: K, the number of attention heads\n",
        "        is_concat: whether the multi-head results should be concatenated or averaged\n",
        "        dropout: the dropout probability\n",
        "        alpha: the negative slope for leaky relu activation\n",
        "        \"\"\"\n",
        "        super(GraphAttentionLayer, self).__init__()\n",
        "\n",
        "        self.is_concat = is_concat\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        if is_concat:\n",
        "            assert out_features % n_heads == 0\n",
        "            self.n_hidden = out_features // n_heads\n",
        "        else:\n",
        "            self.n_hidden = out_features\n",
        "\n",
        "        # TODO: initialize the following modules:\n",
        "        # (1) self.W: Linear layer that transform the input feature before self attention.\n",
        "        # You should NOT use for loops for the multiheaded implementation (set bias = Flase)\n",
        "        # (2) self.attention: Linear layer that compute the attention score (set bias = Flase)\n",
        "        # (3) self.activation: Activation function (LeakyReLU whith negative_slope=alpha)\n",
        "        # (4) self.softmax: Softmax function (what's the dim to compute the summation?)\n",
        "        # (5) self.dropout_layer: Dropout function(with ratio=dropout)\n",
        "        ################ your code here ########################\n",
        "        self.W = nn.Linear(in_features, n_heads * self.n_hidden, bias=False)  # (1)\n",
        "        self.attention = nn.Linear(2 * self.n_hidden, 1, bias=False)  # (2)\n",
        "        self.activation = nn.LeakyReLU(negative_slope=alpha)  # (3)\n",
        "        self.softmax = nn.Softmax(dim=1)  # (4), along neighbors\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)  # (5)\n",
        "        ########################################################\n",
        "\n",
        "    def forward(self, h: torch.Tensor, adj_mat: torch.Tensor):\n",
        "        # Number of nodes\n",
        "        n_nodes = h.shape[0]\n",
        "\n",
        "        # TODO:\n",
        "        # (1) calculate s = Wh and reshape it to [n_nodes, n_heads, n_hidden]\n",
        "        #     (you can use tensor.view() function)\n",
        "        # (2) get [s_i || s_j] using tensor.repeat(), repeat_interleave(), torch.cat(), tensor.view()\n",
        "        # (3) apply the attention layer\n",
        "        # (4) apply the activation layer (you will get the attention score e)\n",
        "        # (5) remove the last dimension 1 use tensor.squeeze()\n",
        "        # (6) mask the attention score with the adjacency matrix (if there's no edge, assign it to -inf)\n",
        "        #     note: check the dimensions of e and your adjacency matrix. You may need to use the function unsqueeze()\n",
        "        # (7) apply softmax\n",
        "        # (8) apply dropout_layer\n",
        "        ############## Your code here #########################################\n",
        "        s = self.W(h).view(n_nodes, self.n_heads, self.n_hidden)  # [n_nodes, n_heads, n_hidden]\n",
        "\n",
        "        # (2) Compute pairwise [s_i || s_j] for attention\n",
        "        s_i = s.unsqueeze(1).repeat(1, n_nodes, 1, 1)  # [n_nodes, n_nodes, n_heads, n_hidden]\n",
        "        s_j = s.unsqueeze(0).repeat(n_nodes, 1, 1, 1)  # [n_nodes, n_nodes, n_heads, n_hidden]\n",
        "        s_concat = torch.cat([s_i, s_j], dim=-1)  # [n_nodes, n_nodes, n_heads, 2 * n_hidden]\n",
        "\n",
        "        # (3) Compute attention scores\n",
        "        e = self.attention(s_concat).squeeze(-1)  # [n_nodes, n_nodes, n_heads]\n",
        "\n",
        "        # (4) Apply activation function\n",
        "        e = self.activation(e)\n",
        "\n",
        "        # (5) Mask attention scores with adjacency matrix\n",
        "        mask = adj_mat.unsqueeze(-1).bool()  # [n_nodes, n_nodes, 1]\n",
        "        e = e.masked_fill(~mask, float('-inf'))  # Mask non-adjacent nodes\n",
        "\n",
        "        # (6) Apply softmax\n",
        "        a = self.softmax(e)  # [n_nodes, n_nodes, n_heads]\n",
        "\n",
        "        # (7) Apply dropout\n",
        "        a = self.dropout_layer(a)\n",
        "        #######################################################################\n",
        "\n",
        "        # Summation\n",
        "        h_prime = torch.einsum('ijh,jhf->ihf', a, s) #[n_nodes, n_heads, n_hidden]\n",
        "\n",
        "\n",
        "        # TODO: Concat or Mean\n",
        "        # Concatenate the heads\n",
        "        if self.is_concat:\n",
        "            ############## Your code here #########################################\n",
        "            h_prime = h_prime.reshape(n_nodes, -1)  # [n_nodes, n_heads * n_hidden]\n",
        "\n",
        "            #######################################################################\n",
        "        # Take the mean of the heads (for the last layer)\n",
        "        else:\n",
        "            ############## Your code here #########################################\n",
        "            h_prime = h_prime.mean(dim=1)  # [n_nodes, n_hidden]\n",
        "            #######################################################################\n",
        "\n",
        "        return h_prime\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOSk_ZShi2nR"
      },
      "source": [
        "## Part 1.2: Define GAT network\n",
        "it's really similar to how we defined GCN. You can follow the paper to set the number of attention layers and the activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jKNbUtPVi1Vs"
      },
      "outputs": [],
      "source": [
        "class GAT(nn.Module):\n",
        "\n",
        "    def __init__(self, nfeat: int, n_hidden: int, n_classes: int, n_heads: int, dropout: float, alpha: float):\n",
        "        \"\"\"\n",
        "        in_features: the number of features per node\n",
        "        n_hidden: the number of features in the first graph attention layer\n",
        "        n_classes: the number of classes\n",
        "        n_heads: the number of heads in the graph attention layers\n",
        "        dropout: the dropout probability\n",
        "        alpha: the negative input slope for leaky ReLU of the attention layer\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO: Set your GraphAttentionLayers, activation function and possibly extensions (such as Dropout)\n",
        "        # First Graph Attention Layer\n",
        "        self.gat1 = GraphAttentionLayer(\n",
        "            in_features=nfeat,\n",
        "            out_features=n_hidden * n_heads,  # Output features per head multiplied by the number of heads\n",
        "            n_heads=n_heads,\n",
        "            is_concat=True,\n",
        "            dropout=dropout,\n",
        "            alpha=alpha\n",
        "        )\n",
        "\n",
        "        # Second Graph Attention Layer (output layer)\n",
        "        self.gat2 = GraphAttentionLayer(\n",
        "            in_features=n_hidden * n_heads,  # Matches the output of the first layer\n",
        "            out_features=n_classes,  # Directly outputs class logits\n",
        "            n_heads=1,  # Single head for the output layer\n",
        "            is_concat=False,  # Averaging for the final layer\n",
        "            dropout=dropout,\n",
        "            alpha=alpha\n",
        "        )\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, adj_mat: torch.Tensor):\n",
        "        \"\"\"\n",
        "        x: the features vectors\n",
        "        adj_mat: the adjacency matrix\n",
        "        \"\"\"\n",
        "        # TODO: implement the forward function\n",
        "        # Apply dropout to input features\n",
        "        x = self.dropout_layer(x)\n",
        "\n",
        "        # First Graph Attention Layer\n",
        "        x = self.gat1(x, adj_mat)\n",
        "        x = F.elu(x)  # Apply ELU activation\n",
        "\n",
        "        # Apply dropout to hidden features\n",
        "        x = self.dropout_layer(x)\n",
        "\n",
        "        # Second Graph Attention Layer\n",
        "        x = self.gat2(x, adj_mat)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)  # Log-softmax for classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtRQ3Ced7RAw"
      },
      "source": [
        "## Part 1.3: Training GAT\n",
        "\n",
        "Play with the structure and the experiment settings and report your results as stated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "b7D5mYXC6zTG"
      },
      "outputs": [],
      "source": [
        "# TODO: SET YOUR HYPERPARAMETERS HERE\n",
        "args = {\n",
        "    \"nfeat\": features.shape[1],         # Number of input features\n",
        "    \"n_hidden\": 8,                      # Number of hidden units per attention head\n",
        "    \"n_classes\": labels.max().item() + 1,  # Number of classes\n",
        "    \"n_heads\": 8,                       # Number of attention heads in the first layer\n",
        "    \"dropout\": 0.6,                     # Dropout probability\n",
        "    \"alpha\": 0.2,                       # Negative slope for LeakyReLU\n",
        "    \"epochs\": 200,                      # Number of training epochs\n",
        "    \"lr\": 0.005,                        # Learning rate\n",
        "    \"weight_decay\": 5e-4,               # L2 regularization\n",
        "    \"training_samples\": 2160            # Fraction of training samples\n",
        "}\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7MYaK98hDy7u",
        "outputId": "c89ab845-5196-4194-e04b-c3a64fd0842e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cora dataset...\n"
          ]
        }
      ],
      "source": [
        "# TODO: SET YOUR MODE AND OPTIMIZER HERE\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = GAT(\n",
        "    nfeat=args[\"nfeat\"],\n",
        "    n_hidden=args[\"n_hidden\"],\n",
        "    n_classes=args[\"n_classes\"],\n",
        "    n_heads=args[\"n_heads\"],\n",
        "    dropout=args[\"dropout\"],\n",
        "    alpha=args[\"alpha\"]\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=args[\"lr\"],\n",
        "    weight_decay=args[\"weight_decay\"]\n",
        ")\n",
        "\n",
        "adj, features, labels, idx_train, idx_val = load_data(training_samples=args[\"training_samples\"])\n",
        "adj, features, labels, idx_train, idx_val = adj.to(device), features.to(device), labels.to(device), idx_train.to(device), idx_val.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train(epoch):\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(features, adj)\n",
        "    loss_train = criterion(output[idx_train], labels[idx_train])\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(features, adj)\n",
        "        loss_val = criterion(output[idx_val], labels[idx_val])\n",
        "        acc_val = accuracy(output[idx_val], labels[idx_val])\n",
        "\n",
        "    print(f'Epoch: {epoch+1:04d}, '\n",
        "          f'Loss: {loss_train.item():.4f}, '\n",
        "          f'Validation Loss: {loss_val.item():.4f}, '\n",
        "          f'Validation Accuracy: {acc_val:.4f}')\n",
        "\n",
        "# Accuracy function\n",
        "def accuracy(output, labels):\n",
        "    preds = output.argmax(dim=1)\n",
        "    correct = (preds == labels).sum().item()\n",
        "    return correct / labels.size(0)\n",
        "\n",
        "\n",
        "# Testing\n",
        "def test():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(features, adj)\n",
        "        acc_test = accuracy(output[idx_val], labels[idx_val])\n",
        "        print(f'Test Accuracy: {acc_test:.4f}')"
      ],
      "metadata": {
        "id": "QyHo-hRxLvsA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ],
      "metadata": {
        "id": "ZTUS1DsjN8Vw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "E9FcfXwMDzEt",
        "collapsed": true,
        "outputId": "3c04937a-3ed1-4fb2-ba40-09334ef2801d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001, Loss: 1.9461, Validation Loss: 1.9418, Validation Accuracy: 0.4142\n",
            "Epoch: 0002, Loss: 1.9417, Validation Loss: 1.9375, Validation Accuracy: 0.3741\n",
            "Epoch: 0003, Loss: 1.9374, Validation Loss: 1.9327, Validation Accuracy: 0.3668\n",
            "Epoch: 0004, Loss: 1.9323, Validation Loss: 1.9275, Validation Accuracy: 0.3650\n",
            "Epoch: 0005, Loss: 1.9283, Validation Loss: 1.9218, Validation Accuracy: 0.3631\n",
            "Epoch: 0006, Loss: 1.9222, Validation Loss: 1.9156, Validation Accuracy: 0.3577\n",
            "Epoch: 0007, Loss: 1.9142, Validation Loss: 1.9088, Validation Accuracy: 0.3540\n",
            "Epoch: 0008, Loss: 1.9067, Validation Loss: 1.9015, Validation Accuracy: 0.3522\n",
            "Epoch: 0009, Loss: 1.9005, Validation Loss: 1.8936, Validation Accuracy: 0.3504\n",
            "Epoch: 0010, Loss: 1.8910, Validation Loss: 1.8852, Validation Accuracy: 0.3485\n",
            "Epoch: 0011, Loss: 1.8808, Validation Loss: 1.8762, Validation Accuracy: 0.3449\n",
            "Epoch: 0012, Loss: 1.8711, Validation Loss: 1.8667, Validation Accuracy: 0.3431\n",
            "Epoch: 0013, Loss: 1.8651, Validation Loss: 1.8567, Validation Accuracy: 0.3412\n",
            "Epoch: 0014, Loss: 1.8564, Validation Loss: 1.8462, Validation Accuracy: 0.3412\n",
            "Epoch: 0015, Loss: 1.8455, Validation Loss: 1.8353, Validation Accuracy: 0.3376\n",
            "Epoch: 0016, Loss: 1.8365, Validation Loss: 1.8241, Validation Accuracy: 0.3376\n",
            "Epoch: 0017, Loss: 1.8277, Validation Loss: 1.8124, Validation Accuracy: 0.3394\n",
            "Epoch: 0018, Loss: 1.8161, Validation Loss: 1.8004, Validation Accuracy: 0.3412\n",
            "Epoch: 0019, Loss: 1.7974, Validation Loss: 1.7881, Validation Accuracy: 0.3431\n",
            "Epoch: 0020, Loss: 1.7919, Validation Loss: 1.7755, Validation Accuracy: 0.3485\n",
            "Epoch: 0021, Loss: 1.7775, Validation Loss: 1.7627, Validation Accuracy: 0.3485\n",
            "Epoch: 0022, Loss: 1.7774, Validation Loss: 1.7497, Validation Accuracy: 0.3522\n",
            "Epoch: 0023, Loss: 1.7638, Validation Loss: 1.7366, Validation Accuracy: 0.3577\n",
            "Epoch: 0024, Loss: 1.7544, Validation Loss: 1.7233, Validation Accuracy: 0.3650\n",
            "Epoch: 0025, Loss: 1.7448, Validation Loss: 1.7100, Validation Accuracy: 0.3759\n",
            "Epoch: 0026, Loss: 1.7237, Validation Loss: 1.6966, Validation Accuracy: 0.3832\n",
            "Epoch: 0027, Loss: 1.7241, Validation Loss: 1.6832, Validation Accuracy: 0.3905\n",
            "Epoch: 0028, Loss: 1.7044, Validation Loss: 1.6697, Validation Accuracy: 0.4015\n",
            "Epoch: 0029, Loss: 1.6981, Validation Loss: 1.6562, Validation Accuracy: 0.4161\n",
            "Epoch: 0030, Loss: 1.6839, Validation Loss: 1.6426, Validation Accuracy: 0.4380\n",
            "Epoch: 0031, Loss: 1.6645, Validation Loss: 1.6289, Validation Accuracy: 0.4526\n",
            "Epoch: 0032, Loss: 1.6639, Validation Loss: 1.6152, Validation Accuracy: 0.4726\n",
            "Epoch: 0033, Loss: 1.6279, Validation Loss: 1.6013, Validation Accuracy: 0.4799\n",
            "Epoch: 0034, Loss: 1.6334, Validation Loss: 1.5874, Validation Accuracy: 0.4982\n",
            "Epoch: 0035, Loss: 1.6118, Validation Loss: 1.5735, Validation Accuracy: 0.5255\n",
            "Epoch: 0036, Loss: 1.6152, Validation Loss: 1.5596, Validation Accuracy: 0.5474\n",
            "Epoch: 0037, Loss: 1.5786, Validation Loss: 1.5457, Validation Accuracy: 0.5657\n",
            "Epoch: 0038, Loss: 1.5867, Validation Loss: 1.5317, Validation Accuracy: 0.6004\n",
            "Epoch: 0039, Loss: 1.5686, Validation Loss: 1.5177, Validation Accuracy: 0.6113\n",
            "Epoch: 0040, Loss: 1.5544, Validation Loss: 1.5036, Validation Accuracy: 0.6259\n",
            "Epoch: 0041, Loss: 1.5428, Validation Loss: 1.4897, Validation Accuracy: 0.6387\n",
            "Epoch: 0042, Loss: 1.5062, Validation Loss: 1.4756, Validation Accuracy: 0.6551\n",
            "Epoch: 0043, Loss: 1.5161, Validation Loss: 1.4615, Validation Accuracy: 0.6697\n",
            "Epoch: 0044, Loss: 1.5010, Validation Loss: 1.4474, Validation Accuracy: 0.6861\n",
            "Epoch: 0045, Loss: 1.4789, Validation Loss: 1.4331, Validation Accuracy: 0.7044\n",
            "Epoch: 0046, Loss: 1.4838, Validation Loss: 1.4187, Validation Accuracy: 0.7208\n",
            "Epoch: 0047, Loss: 1.4561, Validation Loss: 1.4043, Validation Accuracy: 0.7445\n",
            "Epoch: 0048, Loss: 1.4552, Validation Loss: 1.3897, Validation Accuracy: 0.7591\n",
            "Epoch: 0049, Loss: 1.4510, Validation Loss: 1.3752, Validation Accuracy: 0.7628\n",
            "Epoch: 0050, Loss: 1.4450, Validation Loss: 1.3606, Validation Accuracy: 0.7737\n",
            "Epoch: 0051, Loss: 1.4498, Validation Loss: 1.3462, Validation Accuracy: 0.7810\n",
            "Epoch: 0052, Loss: 1.4273, Validation Loss: 1.3320, Validation Accuracy: 0.7883\n",
            "Epoch: 0053, Loss: 1.4063, Validation Loss: 1.3179, Validation Accuracy: 0.7920\n",
            "Epoch: 0054, Loss: 1.4095, Validation Loss: 1.3039, Validation Accuracy: 0.7974\n",
            "Epoch: 0055, Loss: 1.3813, Validation Loss: 1.2901, Validation Accuracy: 0.8011\n",
            "Epoch: 0056, Loss: 1.3871, Validation Loss: 1.2762, Validation Accuracy: 0.8029\n",
            "Epoch: 0057, Loss: 1.3917, Validation Loss: 1.2628, Validation Accuracy: 0.8066\n",
            "Epoch: 0058, Loss: 1.3737, Validation Loss: 1.2498, Validation Accuracy: 0.8102\n",
            "Epoch: 0059, Loss: 1.3672, Validation Loss: 1.2372, Validation Accuracy: 0.8120\n",
            "Epoch: 0060, Loss: 1.3377, Validation Loss: 1.2246, Validation Accuracy: 0.8139\n",
            "Epoch: 0061, Loss: 1.3255, Validation Loss: 1.2124, Validation Accuracy: 0.8139\n",
            "Epoch: 0062, Loss: 1.3446, Validation Loss: 1.2006, Validation Accuracy: 0.8157\n",
            "Epoch: 0063, Loss: 1.3243, Validation Loss: 1.1890, Validation Accuracy: 0.8139\n",
            "Epoch: 0064, Loss: 1.3062, Validation Loss: 1.1775, Validation Accuracy: 0.8157\n",
            "Epoch: 0065, Loss: 1.2966, Validation Loss: 1.1660, Validation Accuracy: 0.8157\n",
            "Epoch: 0066, Loss: 1.2865, Validation Loss: 1.1550, Validation Accuracy: 0.8175\n",
            "Epoch: 0067, Loss: 1.2675, Validation Loss: 1.1442, Validation Accuracy: 0.8175\n",
            "Epoch: 0068, Loss: 1.2706, Validation Loss: 1.1338, Validation Accuracy: 0.8212\n",
            "Epoch: 0069, Loss: 1.2667, Validation Loss: 1.1236, Validation Accuracy: 0.8212\n",
            "Epoch: 0070, Loss: 1.2577, Validation Loss: 1.1137, Validation Accuracy: 0.8230\n",
            "Epoch: 0071, Loss: 1.2152, Validation Loss: 1.1038, Validation Accuracy: 0.8230\n",
            "Epoch: 0072, Loss: 1.2334, Validation Loss: 1.0943, Validation Accuracy: 0.8230\n",
            "Epoch: 0073, Loss: 1.2308, Validation Loss: 1.0847, Validation Accuracy: 0.8248\n",
            "Epoch: 0074, Loss: 1.2376, Validation Loss: 1.0751, Validation Accuracy: 0.8266\n",
            "Epoch: 0075, Loss: 1.2167, Validation Loss: 1.0656, Validation Accuracy: 0.8266\n",
            "Epoch: 0076, Loss: 1.2160, Validation Loss: 1.0562, Validation Accuracy: 0.8285\n",
            "Epoch: 0077, Loss: 1.2248, Validation Loss: 1.0468, Validation Accuracy: 0.8285\n",
            "Epoch: 0078, Loss: 1.2189, Validation Loss: 1.0376, Validation Accuracy: 0.8285\n",
            "Epoch: 0079, Loss: 1.2049, Validation Loss: 1.0286, Validation Accuracy: 0.8339\n",
            "Epoch: 0080, Loss: 1.1888, Validation Loss: 1.0196, Validation Accuracy: 0.8339\n",
            "Epoch: 0081, Loss: 1.2143, Validation Loss: 1.0108, Validation Accuracy: 0.8303\n",
            "Epoch: 0082, Loss: 1.2157, Validation Loss: 1.0025, Validation Accuracy: 0.8303\n",
            "Epoch: 0083, Loss: 1.1786, Validation Loss: 0.9944, Validation Accuracy: 0.8339\n",
            "Epoch: 0084, Loss: 1.1708, Validation Loss: 0.9865, Validation Accuracy: 0.8339\n",
            "Epoch: 0085, Loss: 1.1516, Validation Loss: 0.9788, Validation Accuracy: 0.8339\n",
            "Epoch: 0086, Loss: 1.1935, Validation Loss: 0.9715, Validation Accuracy: 0.8339\n",
            "Epoch: 0087, Loss: 1.1614, Validation Loss: 0.9643, Validation Accuracy: 0.8358\n",
            "Epoch: 0088, Loss: 1.1717, Validation Loss: 0.9574, Validation Accuracy: 0.8358\n",
            "Epoch: 0089, Loss: 1.1742, Validation Loss: 0.9505, Validation Accuracy: 0.8376\n",
            "Epoch: 0090, Loss: 1.1660, Validation Loss: 0.9437, Validation Accuracy: 0.8394\n",
            "Epoch: 0091, Loss: 1.1262, Validation Loss: 0.9373, Validation Accuracy: 0.8394\n",
            "Epoch: 0092, Loss: 1.1161, Validation Loss: 0.9309, Validation Accuracy: 0.8412\n",
            "Epoch: 0093, Loss: 1.1304, Validation Loss: 0.9248, Validation Accuracy: 0.8412\n",
            "Epoch: 0094, Loss: 1.1228, Validation Loss: 0.9187, Validation Accuracy: 0.8412\n",
            "Epoch: 0095, Loss: 1.1317, Validation Loss: 0.9128, Validation Accuracy: 0.8412\n",
            "Epoch: 0096, Loss: 1.1108, Validation Loss: 0.9072, Validation Accuracy: 0.8431\n",
            "Epoch: 0097, Loss: 1.0937, Validation Loss: 0.9014, Validation Accuracy: 0.8431\n",
            "Epoch: 0098, Loss: 1.1281, Validation Loss: 0.8958, Validation Accuracy: 0.8449\n",
            "Epoch: 0099, Loss: 1.1054, Validation Loss: 0.8902, Validation Accuracy: 0.8449\n",
            "Epoch: 0100, Loss: 1.1223, Validation Loss: 0.8848, Validation Accuracy: 0.8485\n",
            "Epoch: 0101, Loss: 1.0862, Validation Loss: 0.8797, Validation Accuracy: 0.8485\n",
            "Epoch: 0102, Loss: 1.1211, Validation Loss: 0.8748, Validation Accuracy: 0.8504\n",
            "Epoch: 0103, Loss: 1.1061, Validation Loss: 0.8701, Validation Accuracy: 0.8504\n",
            "Epoch: 0104, Loss: 1.1122, Validation Loss: 0.8656, Validation Accuracy: 0.8540\n",
            "Epoch: 0105, Loss: 1.1025, Validation Loss: 0.8611, Validation Accuracy: 0.8540\n",
            "Epoch: 0106, Loss: 1.0940, Validation Loss: 0.8567, Validation Accuracy: 0.8540\n",
            "Epoch: 0107, Loss: 1.1146, Validation Loss: 0.8525, Validation Accuracy: 0.8577\n",
            "Epoch: 0108, Loss: 1.1082, Validation Loss: 0.8485, Validation Accuracy: 0.8595\n",
            "Epoch: 0109, Loss: 1.0797, Validation Loss: 0.8443, Validation Accuracy: 0.8595\n",
            "Epoch: 0110, Loss: 1.0683, Validation Loss: 0.8402, Validation Accuracy: 0.8577\n",
            "Epoch: 0111, Loss: 1.0860, Validation Loss: 0.8361, Validation Accuracy: 0.8577\n",
            "Epoch: 0112, Loss: 1.0763, Validation Loss: 0.8320, Validation Accuracy: 0.8595\n",
            "Epoch: 0113, Loss: 1.0801, Validation Loss: 0.8281, Validation Accuracy: 0.8595\n",
            "Epoch: 0114, Loss: 1.0593, Validation Loss: 0.8242, Validation Accuracy: 0.8595\n",
            "Epoch: 0115, Loss: 1.0397, Validation Loss: 0.8204, Validation Accuracy: 0.8595\n",
            "Epoch: 0116, Loss: 1.0723, Validation Loss: 0.8165, Validation Accuracy: 0.8613\n",
            "Epoch: 0117, Loss: 1.0548, Validation Loss: 0.8128, Validation Accuracy: 0.8613\n",
            "Epoch: 0118, Loss: 1.0842, Validation Loss: 0.8091, Validation Accuracy: 0.8613\n",
            "Epoch: 0119, Loss: 1.0804, Validation Loss: 0.8056, Validation Accuracy: 0.8613\n",
            "Epoch: 0120, Loss: 1.0376, Validation Loss: 0.8021, Validation Accuracy: 0.8613\n",
            "Epoch: 0121, Loss: 1.0770, Validation Loss: 0.7986, Validation Accuracy: 0.8613\n",
            "Epoch: 0122, Loss: 1.0379, Validation Loss: 0.7954, Validation Accuracy: 0.8631\n",
            "Epoch: 0123, Loss: 1.0252, Validation Loss: 0.7925, Validation Accuracy: 0.8631\n",
            "Epoch: 0124, Loss: 1.0488, Validation Loss: 0.7895, Validation Accuracy: 0.8650\n",
            "Epoch: 0125, Loss: 1.0272, Validation Loss: 0.7866, Validation Accuracy: 0.8650\n",
            "Epoch: 0126, Loss: 1.0402, Validation Loss: 0.7837, Validation Accuracy: 0.8668\n",
            "Epoch: 0127, Loss: 1.0365, Validation Loss: 0.7806, Validation Accuracy: 0.8668\n",
            "Epoch: 0128, Loss: 1.0277, Validation Loss: 0.7776, Validation Accuracy: 0.8650\n",
            "Epoch: 0129, Loss: 1.0737, Validation Loss: 0.7747, Validation Accuracy: 0.8650\n",
            "Epoch: 0130, Loss: 1.0470, Validation Loss: 0.7720, Validation Accuracy: 0.8650\n",
            "Epoch: 0131, Loss: 1.0383, Validation Loss: 0.7695, Validation Accuracy: 0.8668\n",
            "Epoch: 0132, Loss: 1.0390, Validation Loss: 0.7669, Validation Accuracy: 0.8668\n",
            "Epoch: 0133, Loss: 1.0249, Validation Loss: 0.7642, Validation Accuracy: 0.8704\n",
            "Epoch: 0134, Loss: 1.0302, Validation Loss: 0.7615, Validation Accuracy: 0.8704\n",
            "Epoch: 0135, Loss: 1.0365, Validation Loss: 0.7589, Validation Accuracy: 0.8704\n",
            "Epoch: 0136, Loss: 1.0287, Validation Loss: 0.7562, Validation Accuracy: 0.8704\n",
            "Epoch: 0137, Loss: 1.0166, Validation Loss: 0.7538, Validation Accuracy: 0.8704\n",
            "Epoch: 0138, Loss: 1.0287, Validation Loss: 0.7514, Validation Accuracy: 0.8704\n",
            "Epoch: 0139, Loss: 1.0339, Validation Loss: 0.7489, Validation Accuracy: 0.8704\n",
            "Epoch: 0140, Loss: 1.0126, Validation Loss: 0.7466, Validation Accuracy: 0.8704\n",
            "Epoch: 0141, Loss: 1.0100, Validation Loss: 0.7443, Validation Accuracy: 0.8723\n",
            "Epoch: 0142, Loss: 1.0332, Validation Loss: 0.7421, Validation Accuracy: 0.8741\n",
            "Epoch: 0143, Loss: 1.0152, Validation Loss: 0.7401, Validation Accuracy: 0.8741\n",
            "Epoch: 0144, Loss: 1.0123, Validation Loss: 0.7379, Validation Accuracy: 0.8741\n",
            "Epoch: 0145, Loss: 0.9986, Validation Loss: 0.7356, Validation Accuracy: 0.8741\n",
            "Epoch: 0146, Loss: 1.0239, Validation Loss: 0.7335, Validation Accuracy: 0.8759\n",
            "Epoch: 0147, Loss: 0.9874, Validation Loss: 0.7315, Validation Accuracy: 0.8759\n",
            "Epoch: 0148, Loss: 0.9984, Validation Loss: 0.7295, Validation Accuracy: 0.8759\n",
            "Epoch: 0149, Loss: 1.0031, Validation Loss: 0.7276, Validation Accuracy: 0.8777\n",
            "Epoch: 0150, Loss: 1.0053, Validation Loss: 0.7259, Validation Accuracy: 0.8777\n",
            "Epoch: 0151, Loss: 1.0296, Validation Loss: 0.7242, Validation Accuracy: 0.8777\n",
            "Epoch: 0152, Loss: 1.0072, Validation Loss: 0.7223, Validation Accuracy: 0.8777\n",
            "Epoch: 0153, Loss: 0.9907, Validation Loss: 0.7203, Validation Accuracy: 0.8777\n",
            "Epoch: 0154, Loss: 1.0287, Validation Loss: 0.7184, Validation Accuracy: 0.8777\n",
            "Epoch: 0155, Loss: 0.9955, Validation Loss: 0.7165, Validation Accuracy: 0.8796\n",
            "Epoch: 0156, Loss: 1.0047, Validation Loss: 0.7147, Validation Accuracy: 0.8796\n",
            "Epoch: 0157, Loss: 0.9832, Validation Loss: 0.7129, Validation Accuracy: 0.8796\n",
            "Epoch: 0158, Loss: 0.9924, Validation Loss: 0.7112, Validation Accuracy: 0.8814\n",
            "Epoch: 0159, Loss: 0.9844, Validation Loss: 0.7096, Validation Accuracy: 0.8814\n",
            "Epoch: 0160, Loss: 0.9951, Validation Loss: 0.7079, Validation Accuracy: 0.8796\n",
            "Epoch: 0161, Loss: 0.9828, Validation Loss: 0.7062, Validation Accuracy: 0.8796\n",
            "Epoch: 0162, Loss: 0.9938, Validation Loss: 0.7047, Validation Accuracy: 0.8796\n",
            "Epoch: 0163, Loss: 0.9620, Validation Loss: 0.7032, Validation Accuracy: 0.8796\n",
            "Epoch: 0164, Loss: 0.9637, Validation Loss: 0.7018, Validation Accuracy: 0.8796\n",
            "Epoch: 0165, Loss: 0.9901, Validation Loss: 0.7004, Validation Accuracy: 0.8796\n",
            "Epoch: 0166, Loss: 0.9547, Validation Loss: 0.6990, Validation Accuracy: 0.8796\n",
            "Epoch: 0167, Loss: 0.9815, Validation Loss: 0.6975, Validation Accuracy: 0.8796\n",
            "Epoch: 0168, Loss: 0.9685, Validation Loss: 0.6962, Validation Accuracy: 0.8796\n",
            "Epoch: 0169, Loss: 0.9411, Validation Loss: 0.6948, Validation Accuracy: 0.8814\n",
            "Epoch: 0170, Loss: 0.9630, Validation Loss: 0.6932, Validation Accuracy: 0.8814\n",
            "Epoch: 0171, Loss: 0.9574, Validation Loss: 0.6915, Validation Accuracy: 0.8814\n",
            "Epoch: 0172, Loss: 1.0095, Validation Loss: 0.6898, Validation Accuracy: 0.8814\n",
            "Epoch: 0173, Loss: 0.9706, Validation Loss: 0.6881, Validation Accuracy: 0.8814\n",
            "Epoch: 0174, Loss: 0.9684, Validation Loss: 0.6865, Validation Accuracy: 0.8814\n",
            "Epoch: 0175, Loss: 0.9823, Validation Loss: 0.6849, Validation Accuracy: 0.8814\n",
            "Epoch: 0176, Loss: 0.9583, Validation Loss: 0.6834, Validation Accuracy: 0.8814\n",
            "Epoch: 0177, Loss: 1.0000, Validation Loss: 0.6818, Validation Accuracy: 0.8814\n",
            "Epoch: 0178, Loss: 0.9702, Validation Loss: 0.6801, Validation Accuracy: 0.8814\n",
            "Epoch: 0179, Loss: 0.9848, Validation Loss: 0.6785, Validation Accuracy: 0.8814\n",
            "Epoch: 0180, Loss: 0.9554, Validation Loss: 0.6768, Validation Accuracy: 0.8814\n",
            "Epoch: 0181, Loss: 0.9685, Validation Loss: 0.6752, Validation Accuracy: 0.8796\n",
            "Epoch: 0182, Loss: 0.9989, Validation Loss: 0.6737, Validation Accuracy: 0.8796\n",
            "Epoch: 0183, Loss: 1.0041, Validation Loss: 0.6724, Validation Accuracy: 0.8796\n",
            "Epoch: 0184, Loss: 0.9540, Validation Loss: 0.6711, Validation Accuracy: 0.8796\n",
            "Epoch: 0185, Loss: 0.9734, Validation Loss: 0.6698, Validation Accuracy: 0.8796\n",
            "Epoch: 0186, Loss: 0.9838, Validation Loss: 0.6686, Validation Accuracy: 0.8796\n",
            "Epoch: 0187, Loss: 0.9627, Validation Loss: 0.6673, Validation Accuracy: 0.8796\n",
            "Epoch: 0188, Loss: 0.9884, Validation Loss: 0.6661, Validation Accuracy: 0.8796\n",
            "Epoch: 0189, Loss: 0.9877, Validation Loss: 0.6649, Validation Accuracy: 0.8796\n",
            "Epoch: 0190, Loss: 0.9351, Validation Loss: 0.6636, Validation Accuracy: 0.8796\n",
            "Epoch: 0191, Loss: 0.9455, Validation Loss: 0.6623, Validation Accuracy: 0.8796\n",
            "Epoch: 0192, Loss: 0.9594, Validation Loss: 0.6612, Validation Accuracy: 0.8796\n",
            "Epoch: 0193, Loss: 0.9519, Validation Loss: 0.6600, Validation Accuracy: 0.8814\n",
            "Epoch: 0194, Loss: 0.9669, Validation Loss: 0.6590, Validation Accuracy: 0.8814\n",
            "Epoch: 0195, Loss: 0.9610, Validation Loss: 0.6581, Validation Accuracy: 0.8814\n",
            "Epoch: 0196, Loss: 0.9626, Validation Loss: 0.6574, Validation Accuracy: 0.8832\n",
            "Epoch: 0197, Loss: 0.9617, Validation Loss: 0.6566, Validation Accuracy: 0.8832\n",
            "Epoch: 0198, Loss: 0.9675, Validation Loss: 0.6561, Validation Accuracy: 0.8832\n",
            "Epoch: 0199, Loss: 0.9584, Validation Loss: 0.6556, Validation Accuracy: 0.8832\n",
            "Epoch: 0200, Loss: 0.9907, Validation Loss: 0.6552, Validation Accuracy: 0.8832\n",
            "Optimization Finished!\n",
            "Total time elapsed: 126.0637s\n",
            "Test Accuracy: 0.8832\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "t_total = time.time()\n",
        "for epoch in range(args[\"epochs\"]):\n",
        "    train(epoch)\n",
        "print(\"Optimization Finished!\")\n",
        "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
        "\n",
        "# Testing\n",
        "test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6Ox3fbTG7rc"
      },
      "source": [
        "# Question: (Your task)\n",
        "Compare the evaluation results for Vanilla GCN (from the tutorial session) and GAT. Comment on the discrepancy in their performance (if any) and briefly explain why you think it's the case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI6dkdNWVoT_"
      },
      "source": [
        "**Your answer here:**\n",
        "GCN uses a fixed aggregation, while GAT uses learnable attention weights. GAT performs better as it assigns importance to neighbors dynamically and catches the relationships more succesfully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWrpyuAOIUY_"
      },
      "source": [
        "## Part 2: Transformers\n",
        "\n",
        "In the tutorial session, you learned how to use a transformer model for language modeling. This is a type of decoder-only model, where we directly use the input embeddings to generate text. Here, we will focus on a different task instead: translation. To do this, we will need to use an encoder-decoder architecture.\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nba3UGWpIUY_"
      },
      "source": [
        "### Part 2.1: Transformer Layers\n",
        "\n",
        "Here, you will need to implement a few different layers.\n",
        "1) A multi-head attention block.\n",
        "2) A feedforward network.\n",
        "3) A positional encoding (in the tutorial we used a learned positional encoding. In this assignment, you should implement a sinusoidal positional encoding).\n",
        "\n",
        "***Note that the template code provided for you below is only a template, and you may modify the parameters for the functions as needed.***\n",
        "\n",
        "Once you have these, you will need to combine them together into an encoder and a decoder. Each of these should have $N$ sets of multi-head attention + feedforward. However, the encoder and decoder have to be implemented slightly differently, as the decoder requires masking.\n",
        "\n",
        "Additionally, since this is a translation task, we will need two sets of word embeddings (the input embeddings corresponding to the starting language, and the output embeddings corresponding to the translated language).\n",
        "\n",
        "#### Multi-Head Attention\n",
        "Multi-head attention should be implemented slightly differently here, compared to the tutorial. Specifically, your multi-head attention implementation should allow for masking. This means that if an input mask is provided, everything that is masked out (a value of $0$ in the mask) should not contribute to the attention calculations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCUL8aJkIUY_"
      },
      "source": [
        "It is crucial that the decoder is properly masked. This is because we do not want to allow the decoder to apply attention to output positions it has not seen yet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S8m1PljIUY_"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, input_dimension, hidden_dim, num_heads):\n",
        "        super().__init__()\n",
        "        # TODO\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # TODO\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, input_dimension, hidden_dim, output_dim, n_layers, dropout=0.0):\n",
        "        super().__init__()\n",
        "        # TODO\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, hidden_dim, max_len=5000):\n",
        "        super().__init__()\n",
        "        # TODO\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isT1mBP5IUY_"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_heads, num_layers, output_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # TODO\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # TODO\n",
        "\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_heads, num_layers, output_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdDi4ql2IUY_"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_heads, num_layers, output_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        # TODO\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M78lr2nxIUY_"
      },
      "source": [
        "### Part 2.2: Training the Transformer\n",
        "\n",
        "We will be training our transformer on English -> Turkish translation. In the provided dataset, there are files labeled `{language}.{split}`, for example `en.train`. These are paired data, meaning that each line in the english file has the corresponding translation in the turkish file. There are also 0.5, 0.25, and 0.125 files, which correspond to smaller versions of the training data. Based on training times you encounter, you can use the smaller versions if needed.\n",
        "\n",
        "As with the language modeling task, the model will output logits for each word, which you will then use for the loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs_rcKPfIUY_"
      },
      "source": [
        "#### Setting up the Data\n",
        "\n",
        "Here, we will use word tokens, similar to the RNN assignment. However, you will need to have two sets of tokens, one for the starting language and one for the ending language. You are free to copy the data loading code from assignment 3 and make the necessary modifications, or you may implement the data loading in your own way. However, since we are no longer using fixed length sentences, you will need to implement padding (recall assignment 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGPNIJ06IUY_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNQ8naeYIUY_"
      },
      "source": [
        "#### Training the Model\n",
        "\n",
        "To train the model, you can use a similar approach to the tutorial. However, to calculate the loss, you will need both the source and target language tokens.\n",
        "\n",
        "You should test with multiple sets of hyperparameters and provide the values and results of the best set on the validation data. For this, you should implement a function to calculate the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG2g68uGIUZA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbDe5yj1IUZA"
      },
      "source": [
        "### Part 2.3: Attention Visualization\n",
        "\n",
        "We will now set up some attention visualization, in order to understand what the model has learned. Given an input of length `N`, an attention map is an `N x N` matrix, where the $(i, j)$ value represents the strength of the attention between the i-th input and the j-th input.\n",
        "\n",
        "In order to get the attention maps, you should take the output of each head of the multi-head attention at each layer of the model. The provided function below will help visualize the attention maps given some input data. Run this and include some results on different heads/different layers of the model. Given an explanation of what the results mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6o9ac_vIUZA"
      },
      "outputs": [],
      "source": [
        "# Here, input_data should be the list of input tokens (in text form, not integers), attn_maps are the attention maps, and idx is the batch index\n",
        "def plot_attention_maps(input_data, attn_maps, idx=0):\n",
        "    if input_data is not None:\n",
        "        input_data = input_data[idx].detach().cpu().numpy()\n",
        "    else:\n",
        "        input_data = np.arange(attn_maps[0][idx].shape[-1])\n",
        "    attn_maps = [m[idx].detach().cpu().numpy() for m in attn_maps]\n",
        "\n",
        "    num_heads = attn_maps[0].shape[0]\n",
        "    num_layers = len(attn_maps)\n",
        "    seq_len = input_data.shape[0]\n",
        "    fig_size = 4 if num_heads == 1 else 3\n",
        "    fig, ax = plt.subplots(num_layers, num_heads, figsize=(num_heads*fig_size, num_layers*fig_size))\n",
        "    if num_layers == 1:\n",
        "        ax = [ax]\n",
        "    if num_heads == 1:\n",
        "        ax = [[a] for a in ax]\n",
        "    for row in range(num_layers):\n",
        "        for column in range(num_heads):\n",
        "            ax[row][column].imshow(attn_maps[row][column], origin='lower', vmin=0)\n",
        "            ax[row][column].set_xticks(list(range(seq_len)))\n",
        "            ax[row][column].set_xticklabels(input_data.tolist())\n",
        "            ax[row][column].set_yticks(list(range(seq_len)))\n",
        "            ax[row][column].set_yticklabels(input_data.tolist())\n",
        "            ax[row][column].set_title(f\"Layer {row+1}, Head {column+1}\")\n",
        "    fig.subplots_adjust(hspace=0.5)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDxbKuJcVoT_"
      },
      "source": [
        "# What to submit\n",
        "\n",
        "As in previous assignments, you have several options on how you can make the submission. The important part is, we need to see your code and your results in order to be able to grade you properly.\n",
        "\n",
        "- You can write the answers and experiment results to your notebook and turn it into a pdf and submit it.\n",
        "- You can put your experiment results and explanations to a seperate file as a report, and submit this report and the notebook pdf together.\n",
        "- As long as we can see your code and also the experiment results and answers, you will be fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YY3ZOBE9IUZE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esv21BaOtpOU"
      },
      "source": [
        "# Late Policy\n",
        "You may use up to 7 grace days over the course of the semester for the |assignments you will take. You can only use up to 3 grace days per assignment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eiab3C-Ztxg_"
      },
      "source": [
        "# Academic Integrity\n",
        "All work on assignments must be done individually unless stated otherwise. Turning in someone else’s work, in whole or in part, as your own will be considered as a violation of academic integrity. Please note that the former condition also holds for the material found on the web as everything on the web has been written by someone else.\n",
        "\n",
        "## Acknowledgements\n",
        "Adapted from University of Toronto, Neural Networks and Deep Learning course (CSC413/2516)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}